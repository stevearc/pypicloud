# -*- coding: utf-8 -*-
""" Tests for package storage backends """
import json
import os
import re
import shutil
import sys
import tempfile
import time
import unittest
from io import BytesIO
from urllib.parse import parse_qs, urlparse

import boto3
import vcr
from botocore.exceptions import ClientError
from mock import ANY, MagicMock, patch
from moto import mock_s3

from pypicloud.dateutil import utcnow
from pypicloud.models import Package
from pypicloud.storage import (
    CloudFrontS3Storage,
    FileStorage,
    GoogleCloudStorage,
    S3Storage,
    get_storage_impl,
)
from pypicloud.util import EnvironSettings

from . import make_package


class TestS3Storage(unittest.TestCase):

    """Tests for storing packages in S3"""

    def setUp(self):
        super(TestS3Storage, self).setUp()
        self.s3_mock = mock_s3()
        self.s3_mock.start()
        self.settings = EnvironSettings(
            {
                "storage.bucket": "mybucket",
                "storage.aws_access_key_id": "abc",
                "storage.aws_secret_access_key": "bcd",
            },
            {},
        )
        self.s3 = boto3.resource("s3")
        self.bucket = self.s3.create_bucket(Bucket="mybucket")
        patch.object(S3Storage, "test", True).start()
        kwargs = S3Storage.configure(self.settings)
        self.storage = S3Storage(MagicMock(), **kwargs)

    def tearDown(self):
        super(TestS3Storage, self).tearDown()
        patch.stopall()
        self.s3_mock.stop()

    def test_list(self):
        """Can construct a package from a S3 Key"""
        name, version, filename, summary, uploader = (
            "mypkg",
            "1.2",
            "pkg.tar.gz",
            "text",
            "mypkg_uploader",
        )
        key = self.bucket.Object(name + "/" + filename)
        key.put(
            Metadata={
                "name": name,
                "version": version,
                "summary": summary,
                "uploader": uploader,
            },
            Body="foobar",
        )
        package = list(self.storage.list(Package))[0]
        self.assertEqual(package.name, name)
        self.assertEqual(package.version, version)
        self.assertEqual(package.filename, filename)
        self.assertEqual(package.summary, summary)
        self.assertEqual(package.uploader, uploader)

    def test_list_no_metadata(self):
        """Test that list works on old keys with no metadata"""
        name, version = "mypkg", "1.2"
        filename = "%s-%s.tar.gz" % (name, version)
        key = self.bucket.Object(name + "/" + filename)
        key.put(Body="foobar")
        package = list(self.storage.list(Package))[0]
        self.assertEqual(package.name, name)
        self.assertEqual(package.version, version)
        self.assertEqual(package.filename, filename)
        self.assertEqual(package.summary, None)

    def test_get_url(self):
        """Mock s3 and test package url generation"""
        package = make_package()
        response = self.storage.download_response(package)

        parts = urlparse(response.location)
        self.assertEqual(parts.scheme, "https")
        self.assertEqual(parts.hostname, "mybucket.s3.amazonaws.com")
        self.assertEqual(parts.path, "/" + self.storage.get_path(package))
        query = parse_qs(parts.query)
        self.assertCountEqual(query.keys(), ["Expires", "Signature", "AWSAccessKeyId"])
        self.assertTrue(int(query["Expires"][0]) > time.time())
        self.assertEqual(
            query["AWSAccessKeyId"][0], self.settings["storage.aws_access_key_id"]
        )

    def test_delete(self):
        """delete() should remove package from storage"""
        package = make_package()
        self.storage.upload(package, BytesIO())
        self.storage.delete(package)
        keys = list(self.bucket.objects.all())
        self.assertEqual(len(keys), 0)

    def test_upload(self):
        """Uploading package sets metadata and sends to S3"""
        package = make_package(requires_python="3.6")
        datastr = b"foobar"
        data = BytesIO(datastr)
        self.storage.upload(package, data)
        key = list(self.bucket.objects.all())[0].Object()
        contents = BytesIO()
        key.download_fileobj(contents)
        self.assertEqual(contents.getvalue(), datastr)
        self.assertEqual(key.metadata["name"], package.name)
        self.assertEqual(key.metadata["version"], package.version)
        self.assertEqual(key.metadata["summary"], package.summary)
        self.assertEqual(key.metadata["uploader"], package.uploader)
        self.assertDictContainsSubset(
            package.get_metadata(), Package.read_metadata(key.metadata)
        )

    def test_upload_prepend_hash(self):
        """If prepend_hash = True, attach a hash to the file path"""
        self.storage.prepend_hash = True
        package = make_package()
        data = BytesIO()
        self.storage.upload(package, data)
        key = list(self.bucket.objects.all())[0]

        pattern = r"^[0-9a-f]{4}/%s/%s$" % (
            re.escape(package.name),
            re.escape(package.filename),
        )
        match = re.match(pattern, key.key)
        self.assertIsNotNone(match)

    def test_create_bucket_eu(self):
        """If S3 bucket doesn't exist, create it"""
        settings = EnvironSettings(
            {
                "storage.bucket": "new_bucket",
                "storage.region_name": "eu-central-1",
                "signature_version": "s3v4",
            },
            {},
        )
        S3Storage.configure(settings)

        bucket = self.s3.Bucket("new_bucket")
        bucket.load()

    def test_create_bucket_us(self):
        """If S3 bucket doesn't exist, create it"""
        settings = EnvironSettings(
            {"storage.bucket": "new_bucket", "storage.region_name": "us-west-1"}, {}
        )
        S3Storage.configure(settings)

        bucket = self.s3.Bucket("new_bucket")
        bucket.load()

    def test_object_acl(self):
        """Can specify an object ACL for S3 objects"""
        settings = self.settings.clone()
        settings["storage.object_acl"] = "authenticated-read"
        kwargs = S3Storage.configure(settings)
        storage = S3Storage(MagicMock(), **kwargs)
        package = make_package()
        storage.upload(package, BytesIO())
        acl = list(self.bucket.objects.all())[0].Object().Acl()
        self.assertCountEqual(
            acl.grants,
            [
                {
                    "Grantee": {"Type": "CanonicalUser", "ID": ANY},
                    "Permission": "FULL_CONTROL",
                },
                {
                    "Grantee": {
                        "Type": "Group",
                        "URI": "http://acs.amazonaws.com/groups/global/AuthenticatedUsers",
                    },
                    "Permission": "READ",
                },
            ],
        )

    def test_storage_class(self):
        """Can specify a storage class for S3 objects"""
        settings = self.settings.clone()
        settings["storage.storage_class"] = "STANDARD_IA"
        kwargs = S3Storage.configure(settings)
        storage = S3Storage(MagicMock(), **kwargs)
        package = make_package()
        storage.upload(package, BytesIO())
        storage_class = list(self.bucket.objects.all())[0].Object().storage_class
        self.assertCountEqual(storage_class, "STANDARD_IA")

    def test_check_health_success(self):
        """check_health returns True for good connection"""
        ok, msg = self.storage.check_health()
        self.assertTrue(ok)

    def test_check_health_fail(self):
        """check_health returns False for bad connection"""
        dbmock = self.storage.bucket.meta.client = MagicMock()

        def throw(*_, **__):
            """Throw an exception"""
            raise ClientError({"Error": {}}, "OP")

        dbmock.head_bucket.side_effect = throw
        ok, msg = self.storage.check_health()
        self.assertFalse(ok)

    def test_unicode_summary(self):
        """Unicode characters in summary will be converted to ascii"""
        package = make_package(summary="text ðŸ¤ª")
        datastr = b"foobar"
        data = BytesIO(datastr)
        self.storage.upload(package, data)
        key = list(self.bucket.objects.all())[0].Object()
        contents = BytesIO()
        key.download_fileobj(contents)
        self.assertEqual(contents.getvalue(), datastr)
        self.assertEqual(key.metadata["name"], package.name)
        self.assertEqual(key.metadata["version"], package.version)
        self.assertEqual(key.metadata["summary"], "text ")


class TestCloudFrontS3Storage(unittest.TestCase):

    """Tests for storing packages on S3 with CloudFront in front"""

    def setUp(self):
        super(TestCloudFrontS3Storage, self).setUp()
        self.s3_mock = mock_s3()
        self.s3_mock.start()
        self.settings = EnvironSettings(
            {
                "storage.bucket": "mybucket",
                "storage.aws_access_key_id": "abc",
                "storage.aws_secret_access_key": "bcd",
                "storage.cloud_front_domain": "https://abcdef.cloudfront.net",
                "storage.cloud_front_key_file": "",
                "storage.cloud_front_key_string": "-----BEGIN RSA PRIVATE KEY-----\n"
                "MIICXQIBAAKBgQDNBN3WHzIgmOEkBVNdBlTR7iGYyUXDVuFRkJlYp/n1/EZf2YtE\n"
                "BpxJAgqdwej8beWV16QXOnKXQpsGAeu7x2pvOGFyRGytmLDeUXayfIF/E46w83V2\n"
                "r53NOBrlezagqCAz9uafocyNaXlxZfp4tx82sEmpSmHGwd//+n6zgXNC0QIDAQAB\n"
                "AoGAd5EIA1GMPYCLhSNp+82ueARGKcHwYrzviU8ob5D/cVtge5P26YRlbxq2sEyf\n"
                "oWBCTgJGW5mlrNuWZ4mFPq1NP2X2IU80k/J67KOuOelAykIVQw6q6GAjtmh40x4N\n"
                "EekoFzxVqoFKqWOJ1UNP0jNOyfzxU5dfzvw5GOEXob9usjECQQD3++wWCoq+YRCz\n"
                "8qqav2M7leoAnDwmCYKpnugDU0NR61sZADS3kJHnhXAbPFQI4dRfETJOkKE/iDph\n"
                "G0Rtdfm1AkEA06VoI49wjEMYs4ah3qwpvhuVyxVa9iozIEoDYiVCOOBZw8rX79G4\n"
                "+5yzC9ehy9ugWttSA2jigNXVB6ORN3+mLQJBAM47lZizBbXUdZahvp5ZgoZgY65E\n"
                "QIWFrUOxYtS5Hyh2qlk9YZozwhOgVp5f6qdEYGD7pTHPeDqk6aAulBbQYW0CQQC4\n"
                "hAw2dGd64UQ3v7h/mTkLNKFzXDrhQgkwrVYlyrXhQDcCK2X2/rB3LDYsrOGyCNfU\n"
                "XkEyF87g44vGDSQdbnxBAkA1Y+lB/pqdyHMv5RFabkBvU0yQDfekAKHeQ6rS+21g\n"
                "dWedUVc1JNnKtb8W/rMfdjg9YLYqUTvoBvp0DjfwdYc4\n"
                "-----END RSA PRIVATE KEY-----",
                "storage.cloud_front_key_id": "key-id",
            },
            {},
        )
        s3 = boto3.resource("s3")
        self.bucket = s3.create_bucket(Bucket="mybucket")
        patch.object(CloudFrontS3Storage, "test", True).start()
        kwargs = CloudFrontS3Storage.configure(self.settings)
        self.storage = CloudFrontS3Storage(MagicMock(), **kwargs)

    def test_get_url(self):
        """Mock s3 and test package url generation"""
        package = make_package(version="1.1+g12345")
        response = self.storage.download_response(package)

        parts = urlparse(response.location)
        self.assertEqual(parts.scheme, "https")
        self.assertEqual(parts.netloc, "abcdef.cloudfront.net")
        self.assertEqual(parts.path, "/bcc4/mypkg/mypkg-1.1%2Bg12345.tar.gz")
        query = parse_qs(parts.query)
        self.assertCountEqual(query.keys(), ["Key-Pair-Id", "Expires", "Signature"])
        self.assertTrue(int(query["Expires"][0]) > time.time())
        self.assertEqual(
            query["Key-Pair-Id"][0], self.settings["storage.cloud_front_key_id"]
        )


class TestFileStorage(unittest.TestCase):

    """Tests for storing packages as local files"""

    def setUp(self):
        super(TestFileStorage, self).setUp()
        self.tempdir = tempfile.mkdtemp()
        settings = {"storage.dir": self.tempdir}
        kwargs = FileStorage.configure(settings)
        self.request = MagicMock()
        self.storage = FileStorage(self.request, **kwargs)

    def tearDown(self):
        super(TestFileStorage, self).tearDown()
        shutil.rmtree(self.tempdir)

    def test_upload(self):
        """Uploading package saves file"""
        package = make_package(requires_python="3.6")
        datastr = b"foobar"
        data = BytesIO(datastr)
        self.storage.upload(package, data)
        filename = self.storage.get_path(package)
        self.assertTrue(os.path.exists(filename))
        with open(filename, "r", encoding="utf-8") as ifile:
            self.assertEqual(ifile.read(), "foobar")
        meta_file = self.storage.get_metadata_path(package)
        self.assertTrue(os.path.exists(meta_file))
        with open(meta_file, "r", encoding="utf-8") as mfile:
            self.assertEqual(json.loads(mfile.read()), package.get_metadata())

    def test_list(self):
        """Can iterate over uploaded packages"""
        package = make_package()
        path = self.storage.get_path(package)
        meta_file = self.storage.get_metadata_path(package)
        os.makedirs(os.path.dirname(path))
        with open(path, "w", encoding="utf-8") as ofile:
            ofile.write("foobar")

        with open(meta_file, "w", encoding="utf-8") as mfile:
            mfile.write(
                json.dumps({"summary": package.summary, "uploader": package.uploader})
            )

        pkg = list(self.storage.list(Package))[0]
        self.assertEqual(pkg.name, package.name)
        self.assertEqual(pkg.version, package.version)
        self.assertEqual(pkg.filename, package.filename)
        self.assertEqual(pkg.summary, package.summary)
        self.assertEqual(pkg.uploader, package.uploader)

    def test_delete(self):
        """delete() should remove package from storage"""
        package = make_package()
        path = self.storage.get_path(package)
        meta_path = self.storage.get_metadata_path(package)
        os.makedirs(os.path.dirname(path))
        with open(path, "w", encoding="utf-8") as ofile:
            ofile.write("foobar")
        with open(meta_path, "w", encoding="utf-8") as mfile:
            mfile.write("foobar")
        self.storage.delete(package)
        self.assertFalse(os.path.exists(path))
        self.assertFalse(os.path.exists(meta_path))

    def test_create_package_dir(self):
        """configure() will create the package dir if it doesn't exist"""
        tempdir = tempfile.mkdtemp()
        os.rmdir(tempdir)
        settings = {"storage.dir": tempdir}
        FileStorage.configure(settings)
        try:
            self.assertTrue(os.path.exists(tempdir))
        finally:
            os.rmdir(tempdir)

    def test_check_health(self):
        """Base check_health returns True"""
        ok, msg = self.storage.check_health()
        self.assertTrue(ok)


class MockGCSBlob(object):
    """Mock object representing the google.cloud.storage.Blob class"""

    def __init__(self, name, bucket):
        self.name = name
        self.metadata = {}
        self.updated = None
        self._content = None
        self._acl = None
        self.bucket = bucket
        self.generate_signed_url = MagicMock(wraps=self._generate_signed_url)
        self.upload_from_file = MagicMock(wraps=self._upload_from_file)
        self.delete = MagicMock(wraps=self._delete)
        self.update_storage_class = MagicMock(wraps=self._update_storage_class)

    def upload_from_string(self, s):
        """Utility method for uploading this blob; not used by the
        GoogleCloudStorage backend, but used to pre-populate the GCS
        mock for testing
        """
        self.updated = utcnow()
        self._content = s
        self.bucket._upload_blob(self)

    def _upload_from_file(self, fp, predefined_acl):
        """Mock the upload_from_file() method on google.cloud.storage.Blob"""
        self._acl = predefined_acl
        self.upload_from_string(fp.read())

    def _delete(self):
        """Mock the delete() method on google.cloud.storage.Blob"""
        self.bucket._delete_blob(self.name)

    def _generate_signed_url(self, expiration, credentials, version):
        """Mock the generate_signed_url() method on
        google.cloud.storage.Blob
        """
        return "https://storage.googleapis.com/{bucket_name}/{blob_name}?Expires={expires}&GoogleAccessId=my-service-account%40my-project.iam.gserviceaccount.com&Signature=MySignature".format(
            bucket_name=self.bucket.name,
            blob_name=self.name,
            expires=int(time.time() + expiration.total_seconds()),
        )

    def _update_storage_class(self, storage_class):
        """Mock the update_storage_class() method on google.cloud.storage.Blob.
        This is a NOOP because we only check to make sure that it was
        called, not that it changed any state on the MockGCSBlob class
        """


class MockGCSBucket(object):
    """Mock object representing the google.cloud.storage.Bucket class"""

    def __init__(self, name, client):
        self.name = name
        self.client = client

        self._created = False
        self.location = None

        self.blob = MagicMock(wraps=self._blob)
        self.list_blobs = MagicMock(wraps=self._list_blobs)
        self.exists = MagicMock(wraps=self._exists)
        self.create = MagicMock(wraps=self._create)

        self._blobs = {}

    def _upload_blob(self, blob):
        """Method used by the MockGCSBlob class to register blobs after
        MockGCSBlob.upload is called
        """
        self._blobs[blob.name] = blob

    def _delete_blob(self, blob_name):
        """Method used by the MockGCSBlob class to unregister blobs after
        MockGCSBlob.delete is called
        """
        self._blobs.pop(blob_name)

    def _blob(self, blob_name):
        """Mock the blob() method on google.cloud.storage.Bucket"""
        return MockGCSBlob(blob_name, self)

    def _list_blobs(self, prefix=None):
        """Mock the list_blobs() method on google.cloud.storage.Bucket"""
        return [
            item
            for item in self._blobs.values()
            if prefix is None or item.name.startswith(prefix)
        ]

    def _exists(self):
        """Mock the exists() method on google.cloud.storage.Bucket"""
        return self._created

    def _create(self):
        """Mock the create() method on google.cloud.storage.Bucket"""
        self._created = True


class MockGCSClient(object):
    """Mock object representing the google.cloud.storage.Client class"""

    def __init__(self):
        self.bucket = MagicMock(wraps=self._bucket)

        self._buckets = {}

    def from_service_account_json(self, *args, **kwargs):
        """Mock the from_service_account_json method from the cloud storage
        client class, used by the GoogleCloudStorage backend.
        """
        return self

    def __call__(self):
        """Provide a call() method so that we can easily patch an instance
        of this class in place of the constructor of the mocked class
        """
        return self

    def _bucket(self, bucket_name):
        """Mock the bucket() method on google.cloud.storage.Bucket"""
        if bucket_name not in self._buckets:
            self._buckets[bucket_name] = MockGCSBucket(bucket_name, self)

        return self._buckets[bucket_name]


class TestGoogleCloudStorage(unittest.TestCase):

    """Tests for storing packages in GoogleCloud"""

    def setUp(self):
        super(TestGoogleCloudStorage, self).setUp()
        self.gcs = MockGCSClient()
        self._config_file = tempfile.mktemp()
        with open(self._config_file, "w", encoding="utf-8") as ofile:
            json.dump({}, ofile)
        patch("google.cloud.storage.Client", self.gcs).start()
        self.settings = {
            "storage.bucket": "mybucket",
            "storage.gcp_service_account_json_filename": self._config_file,
        }
        self.bucket = self.gcs.bucket("mybucket")
        self.bucket._created = True
        patch.object(GoogleCloudStorage, "test", True).start()
        kwargs = GoogleCloudStorage.configure(self.settings)
        self.storage = GoogleCloudStorage(MagicMock(), **kwargs)

    def tearDown(self):
        super(TestGoogleCloudStorage, self).tearDown()
        patch.stopall()
        os.remove(self._config_file)

    def test_list(self):
        """Can construct a package from a GoogleCloudStorage Blob"""
        name, version, filename, summary, uploader = (
            "mypkg",
            "1.2",
            "pkg.tar.gz",
            "text",
            "gcs_user",
        )

        blob = self.bucket.blob(name + "/" + filename)
        blob.metadata = {
            "name": name,
            "version": version,
            "summary": summary,
            "uploader": uploader,
        }
        blob.upload_from_string("foobar")

        package = list(self.storage.list(Package))[0]
        self.assertEqual(package.name, name)
        self.assertEqual(package.version, version)
        self.assertEqual(package.filename, filename)
        self.assertEqual(package.summary, summary)
        self.assertEqual(package.uploader, uploader)

        self.gcs.bucket.assert_called_with("mybucket")
        self.bucket.list_blobs.assert_called_with(prefix=None)
        self.assertEqual(self.bucket.create.call_count, 0)

    def test_get_url(self):
        """Mock gcs and test package url generation"""
        package = make_package()
        response = self.storage.download_response(package)

        parts = urlparse(response.location)
        self.assertEqual(parts.scheme, "https")
        self.assertEqual(parts.hostname, "storage.googleapis.com")
        self.assertEqual(parts.path, "/mybucket/" + self.storage.get_path(package))
        query = parse_qs(parts.query)
        self.assertCountEqual(query.keys(), ["Expires", "Signature", "GoogleAccessId"])
        self.assertTrue(int(query["Expires"][0]) > time.time())

    def test_delete(self):
        """delete() should remove package from storage"""
        package = make_package()
        self.storage.upload(package, BytesIO())
        self.storage.delete(package)
        keys = [blob.name for blob in self.bucket.list_blobs()]
        self.assertEqual(len(keys), 0)

    def test_upload(self):
        """Uploading package sets metadata and sends to S3"""
        package = make_package(requires_python="3.6", uploader="gcs_user")
        datastr = b"foobar"
        data = BytesIO(datastr)
        self.storage.upload(package, data)

        blob = self.bucket.list_blobs()[0]
        blob.upload_from_file.assert_called_with(data, predefined_acl=None)

        self.assertEqual(blob._content, datastr)
        self.assertEqual(blob.metadata["name"], package.name)
        self.assertEqual(blob.metadata["version"], package.version)
        self.assertEqual(blob.metadata["uploader"], package.uploader)
        self.assertDictContainsSubset(package.get_metadata(), blob.metadata)

        self.assertEqual(self.bucket.create.call_count, 0)

    def test_upload_prepend_hash(self):
        """If prepend_hash = True, attach a hash to the file path"""
        self.storage.prepend_hash = True
        package = make_package()
        data = BytesIO()
        self.storage.upload(package, data)

        blob = self.bucket.list_blobs()[0]

        pattern = r"^[0-9a-f]{4}/%s/%s$" % (
            re.escape(package.name),
            re.escape(package.filename),
        )
        match = re.match(pattern, blob.name)
        self.assertIsNotNone(match)

    def test_create_bucket(self):
        """If GCS bucket doesn't exist, create it"""
        settings = {
            "storage.bucket": "new_bucket",
            "storage.region_name": "us-east-1",
            "storage.gcp_service_account_json_filename": self._config_file,
        }
        arguments = GoogleCloudStorage.configure(settings)
        arguments["bucket_factory"]()

        self.gcs.bucket.assert_called_with("new_bucket")
        bucket = self.gcs.bucket("new_bucket")
        bucket.create.assert_called_once_with()

    def test_object_acl(self):
        """Can specify an object ACL for GCS objects.  Just test to make
        sure that the configured ACL is forwarded to the API client
        """
        settings = dict(self.settings)
        settings["storage.object_acl"] = "authenticated-read"
        kwargs = GoogleCloudStorage.configure(settings)
        storage = GoogleCloudStorage(MagicMock(), **kwargs)
        package = make_package()
        storage.upload(package, BytesIO())

        blob = self.bucket.list_blobs()[0]
        self.assertEqual(blob._acl, "authenticated-read")

    def test_storage_class(self):
        """Can specify a storage class for GCS objects"""
        settings = dict(self.settings)
        settings["storage.storage_class"] = "COLDLINE"
        kwargs = GoogleCloudStorage.configure(settings)
        storage = GoogleCloudStorage(MagicMock(), **kwargs)
        package = make_package()
        storage.upload(package, BytesIO())

        blob = self.bucket.list_blobs()[0]
        blob.update_storage_class.assert_called_with("COLDLINE")

    def test_client_without_credentials(self):
        """Can create a client without passing in application credentials"""
        kwargs = GoogleCloudStorage.configure(
            {"storage.bucket": "new_bucket", "storage.region_name": "us-east-1"}
        )
        GoogleCloudStorage(MagicMock(), **kwargs)


class TestAzureStorage(unittest.TestCase):
    """Tests for storing packages in Azure Blob Storage"""

    @classmethod
    def setUpClass(cls):
        super(TestAzureStorage, cls).setUpClass()
        if sys.version_info.major < 3 or sys.version_info.minor < 6:
            raise unittest.SkipTest("vcrpy does not work on < 3.6 :(")

    def setUp(self):
        super(TestAzureStorage, self).setUp()
        self.settings = {
            "pypi.storage": "azure-blob",
            "storage.storage_account_name": "terrytest2",
            "storage.storage_account_key": "Aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa==",
            "storage.storage_container_name": "pypi",
        }
        storage_func = get_storage_impl(self.settings)
        self.storage = storage_func(MagicMock())

    def test_list_and_upload(self):
        """List packages from blob storage"""
        with vcr.use_cassette(
            "tests/vcr_cassettes/test_list.yaml", filter_headers=["authorization"]
        ):
            package = make_package(
                "mypkg", "1.2", "pkg.tar.gz", summary="test", uploader="azure_user"
            )
            self.storage.upload(package, BytesIO(b"test1234"))

            pkg = list(self.storage.list(Package))[0]
            self.assertEqual(pkg.name, package.name)
            self.assertEqual(pkg.version, package.version)
            self.assertEqual(pkg.filename, package.filename)
            self.assertEqual(pkg.summary, package.summary)
            self.assertEqual(pkg.uploader, package.uploader)

    def test_get_url(self):
        """Test presigned url generation"""
        package = make_package()
        response = self.storage.download_response(package)

        parts = urlparse(response.location)
        self.assertEqual(parts.scheme, "https")
        self.assertEqual(parts.hostname, "terrytest2.blob.core.windows.net")
        self.assertEqual(
            parts.path,
            "/"
            + self.settings["storage.storage_container_name"]
            + "/"
            + self.storage.get_path(package),
        )
        query = parse_qs(parts.query)
        self.assertCountEqual(query.keys(), ["se", "sp", "spr", "sv", "sr", "sig"])

    def test_delete(self):
        """delete() should remove package from storage"""
        with vcr.use_cassette(
            "tests/vcr_cassettes/test_delete.yaml", filter_headers=["authorization"]
        ):
            package = make_package()
            self.storage.upload(package, BytesIO())
            self.storage.delete(package)
            packages = list(self.storage.list(Package))
            self.assertEqual(len(packages), 0)

    def test_check_health_success(self):
        """check_health returns True for good connection"""
        with vcr.use_cassette(
            "tests/vcr_cassettes/test_check.yaml", filter_headers=["authorization"]
        ):
            ok, msg = self.storage.check_health()
            self.assertTrue(ok)

    def test_check_health_fail(self):
        """check_health returns False for bad connection"""
        with vcr.use_cassette(
            "tests/vcr_cassettes/test_check_fail.yaml",
            filter_headers=["authorization"],
            record_mode="none",
        ):
            ok, msg = self.storage.check_health()
            self.assertFalse(ok)
